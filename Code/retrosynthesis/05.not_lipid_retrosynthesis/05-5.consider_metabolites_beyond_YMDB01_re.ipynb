{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG, display\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import sys\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm import tqdm \n",
    "import cobra\n",
    "from itertools import chain, combinations\n",
    "import sys\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "tqdm.pandas()\n",
    "# sys.path.append('../Code/')\n",
    "sys.path.append('../')\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "num = 50\n",
    "cut_off = 0.3\n",
    "cut_off_retrosynthesis_path = f'../../../Data_retrosynthesis/not_lipid/top{num}_{cut_off}_add_no_ec_re/'\n",
    "cut_off_path = f'../../../Results/not_lipid/top{num}_{cut_off}_add_no_ec_re/'\n",
    "\n",
    "# path = '../Data/output/not_lipid/retrosynthesis/top40_0.3/'\n",
    "not_lipid_rxndb_path = cut_off_retrosynthesis_path + 'RXNdb_top50_0.3/'\n",
    "not_lipid_YMDB_fail_met_smile_uptake_file = cut_off_path + f'YMDB_fail_met_smile_uptake_top{num}_{cut_off}.pickle'\n",
    "total_met_inchikey0_file = '../../../Data/total_met_inchikey0.pickle'\n",
    "YMDB_fail_met_smile_file = cut_off_path + f'YMDB_fail_met_smile_top{num}_{cut_off}.pickle'\n",
    "uptake_met_path = '../../../Data/ymdb/ymdb_uptake.csv'\n",
    "\n",
    "# not_lipid_rxndb_all_no_drop_path = cut_off_path + 'RXNdb_all_no_drop_top50.json'\n",
    "rxndb_path = cut_off_retrosynthesis_path + f'RXNdb_top{num}_{cut_off}/'\n",
    "\n",
    "\n",
    "#output\n",
    "not_lipid_rxndb_inteme_drop_duplicate_path = cut_off_path + f'RXNdb_all_top50_0.3_all.csv'\n",
    "not_lipid_fail_target_rxndb_path = cut_off_retrosynthesis_path + 'RXNdb_fail_target/'\n",
    "not_lipid_rxndb_inteme_only_one_new_path = cut_off_path + 'RXNdb_inteme_only_one_new_top50_drop_unvalid.csv'\n",
    "not_lipid_rxndb_inteme_only_one_new_target_path = cut_off_path + 'RXNdb_inteme_only_one_new_target_top50.csv'\n",
    "\n",
    "sink0_path = cut_off_path + 'sink0_new_met_only_new_one_top50.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(not_lipid_fail_target_rxndb_path):\n",
    "    os.makedirs(not_lipid_fail_target_rxndb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_mer(file,rxndb_path,inchikey0,rxndb_drop_path):\n",
    "    with open(rxndb_path + file, 'r') as f:\n",
    "        rxndb = json.load(f)    \n",
    "    remove = []\n",
    "    for k,v in rxndb.items():\n",
    "        \n",
    "        productsmile = v['productsmile'].split('.')\n",
    "        if any([smiles2inchikey0(p) in inchikey0  for p in productsmile]):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            remove.append(k)\n",
    "    for k in remove:\n",
    "        rxndb.pop(k)\n",
    "    with open(rxndb_drop_path + file, 'w') as f:\n",
    "        json.dump(rxndb, f,indent=4)\n",
    "\n",
    "def drop_rxndb_mer(rxndb_path, rxndb_drop_path, inchikey0,num_processes=60):\n",
    "    files = os.listdir(rxndb_path)\n",
    "    process_file_partial = partial(process_file_mer,rxndb_path=rxndb_path,inchikey0=inchikey0,rxndb_drop_path=rxndb_drop_path)\n",
    "    with mp.Pool(num_processes) as p:\n",
    "        list(tqdm(p.imap_unordered(process_file_partial, files), total=len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_lipid_YMDB_fail_met_smile = pickle.load(open(not_lipid_YMDB_fail_met_smile_uptake_file, 'rb'))\n",
    "not_lipid_YMDB_fail_met_inchikey0 = [smiles2inchikey0(smile) for smile in not_lipid_YMDB_fail_met_smile ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16955/16955 [04:30<00:00, 62.79it/s] \n"
     ]
    }
   ],
   "source": [
    "drop_rxndb_mer(not_lipid_rxndb_path, not_lipid_fail_target_rxndb_path, not_lipid_YMDB_fail_met_inchikey0,num_processes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_drop_duplicate(file,rxndb_path):\n",
    "    try:\n",
    "        with open(rxndb_path + file, 'r') as f:\n",
    "            rxndb = json.load(f)    \n",
    "    \n",
    "        if len(rxndb) != 0:\n",
    "            rxndb_df = pd.DataFrame(rxndb).transpose()\n",
    "            \n",
    "            rxndb_df['reactant_inchikey0'] = rxndb_df['reactant_smile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "            rxndb_df['product_inchikey0'] = rxndb_df['productsmile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "            # rxndb_df['product_inchikey0'] = rxndb_df['product_inchikey0'].apply(lambda x: '.'.join(sorted(x.split('.'))))\n",
    "            # rxndb_df['reactant_inchikey0'] = rxndb_df['reactant_inchikey0'].apply(lambda x: '.'.join(sorted(x.split('.'))))\n",
    "            rxndb = rxndb_df.to_dict(orient='index')\n",
    "            with open(rxndb_path + file, 'w') as f:\n",
    "                json.dump(rxndb, f,indent=4)\n",
    "    except:\n",
    "        print(file)\n",
    "        pass\n",
    "\n",
    "def process_file_drop_duplicate_parallel(rxndb_path,num_processes=50):\n",
    "    files = os.listdir(rxndb_path)\n",
    "#     files = ['RXNdb_14838.json','RXNdb_7284.json','RXNdb_10683.json','RXNdb_10627.json',\n",
    "# 'RXNdb_17365.json','RXNdb_13669.json','RXNdb_14857.json','RXNdb_15735.json','RXNdb_5346.json','RXNdb_7276.json']\n",
    "    process_file_partial = partial(process_file_drop_duplicate,rxndb_path=rxndb_path)\n",
    "    with mp.Pool(num_processes) as p:\n",
    "        list(tqdm(p.imap_unordered(process_file_partial, files), total=len(files)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_rxndb(not_lipid_rxndb_inteme_drop_duplicate_path,rxndb_path):\n",
    "    files = os.listdir(rxndb_path) \n",
    "    with open(rxndb_path + files[0], 'r') as f:\n",
    "        rxndb_total = json.load(f)\n",
    "        rxndb_total_df = pd.DataFrame(rxndb_total).transpose()\n",
    "        # rxndb_total_df['reactant_inchikey0'] = rxndb_total_df['reactant_smile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "        # rxndb_total_df['product_inchikey0'] = rxndb_total_df['productsmile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "        \n",
    "    for file in tqdm(files[1:],total=len(files[1:])):\n",
    "        with open(rxndb_path + file, 'r') as f:\n",
    "            rxndb = json.load(f) \n",
    "    \n",
    "        rxndb_df = pd.DataFrame(rxndb).transpose()\n",
    "        # rxndb_df['reactant_inchikey0'] = rxndb_df['reactant_smile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "        # rxndb_df['product_inchikey0'] = rxndb_df['productsmile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "        rxndb_total_df = pd.concat([rxndb_total_df,rxndb_df],axis=0)\n",
    "    rxndb_total_df = rxndb_total_df.drop_duplicates(subset=['reactant_inchikey0', 'product_inchikey0'], keep='first').reset_index(drop=True)\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_drop_duplicate_path )\n",
    "    print(rxndb_total_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16955/16955 [03:11<00:00, 88.52it/s] \n"
     ]
    }
   ],
   "source": [
    "process_file_drop_duplicate_parallel(not_lipid_fail_target_rxndb_path,num_processes=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16954 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16954/16954 [56:12<00:00,  5.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126778, 11)\n"
     ]
    }
   ],
   "source": [
    "drop_duplicate_rxndb(not_lipid_rxndb_inteme_drop_duplicate_path,not_lipid_fail_target_rxndb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def choose_only_one_new(not_lipid_rxndb_inteme_drop_duplicate_path,total_inchikey0,not_lipid_rxndb_inteme_only_one_new_path):\n",
    "    rxndb_total_df = pd.read_csv(not_lipid_rxndb_inteme_drop_duplicate_path)\n",
    "    rxndb_total_df['new_num'] = None\n",
    "    rxndb_total_df['reactant_inchikey0'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: x.split('.'))\n",
    "    rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: sum([1 for i in x if i not in total_inchikey0 ]))\n",
    "    rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 1]\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_only_one_new_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inchikey0 = load_pickle(total_met_inchikey0_file)\n",
    "choose_only_one_new(not_lipid_rxndb_inteme_drop_duplicate_path,total_inchikey0,not_lipid_rxndb_inteme_only_one_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df):\n",
    "    for index, row in df.iterrows():\n",
    "        reactant_smile = row['reactant_smile'].split('.')\n",
    "        for i in reactant_smile:\n",
    "            if not Chem.MolFromSmiles(i):\n",
    "                df.drop(index, inplace=True)\n",
    "                break\n",
    "    for index, row in df.iterrows():\n",
    "        productsmile = row['productsmile'].split('.')\n",
    "        for i in productsmile:\n",
    "            if not Chem.MolFromSmiles(i):\n",
    "                df.drop(index, inplace=True)\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106869, 14)\n"
     ]
    }
   ],
   "source": [
    "not_lipid_rxndb_inteme_only_one_new = pd.read_csv(not_lipid_rxndb_inteme_only_one_new_path)\n",
    "print(not_lipid_rxndb_inteme_only_one_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106740, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = np.array_split(not_lipid_rxndb_inteme_only_one_new, 50)\n",
    "with mp.Pool(50) as pool:\n",
    "    results = list(tqdm(pool.imap(filter_df, chunks), total=len(chunks)))\n",
    "rxndb_total_df = pd.concat(results)\n",
    "rxndb_total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxndb_total_df.to_csv(not_lipid_rxndb_inteme_only_one_new_target_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
